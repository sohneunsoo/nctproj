{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 20:40:39.758880: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-14 20:40:42.541551: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-04-14 20:40:42.542505: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-04-14 20:40:42.542519: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "import re\n",
    "import gc\n",
    "\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing import sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 4 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 04:53:50.940171: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:50.940630: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:50.940965: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:50.941313: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:50.952801: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:50.953204: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:50.953537: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:50.953859: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:50.954195: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:50.954531: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:50.954907: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:50.955264: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:50.956865: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-14 04:53:51.344258: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:51.344674: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:51.344997: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:51.345323: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:51.345644: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:51.345949: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:51.346292: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:51.346612: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:51.346949: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:51.347275: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:51.347598: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:51.347927: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:53.343826: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:53.344286: I tensorflow/compiler/xla/stream_execu"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:53.344654: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:53.345001: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:53.345353: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:53.345682: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:53.346026: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:53.346397: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:53.346780: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:53.347120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14622 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n",
      "2023-04-14 04:53:53.347728: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:53.348044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14622 MB memory:  -> device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:05.0, compute capability: 7.0\n",
      "2023-04-14 04:53:53.348797: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:53.349120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 14622 MB memory:  -> device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:06.0, compute capability: 7.0\n",
      "2023-04-14 04:53:53.349455: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:53:53.349797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 14622 MB memory:  -> device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:07.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n",
      "/job:localhost/replica:0/task:0/device:GPU:1 -> device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:05.0, compute capability: 7.0\n",
      "/job:localhost/replica:0/task:0/device:GPU:2 -> device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:06.0, compute capability: 7.0\n",
      "/job:localhost/replica:0/task:0/device:GPU:3 -> device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:07.0, compute capability: 7.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 04:54:13.136907: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:54:13.137405: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:54:13.137776: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:54:13.138188: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:54:13.138563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:54:13.138943: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:54:13.139318: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:54:13.139658: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:54:13.140018: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:54:13.140350: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:54:13.140675: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:54:13.141000: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:54:13.141550: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:54:13.141931: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:54:13.142302: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:54:13.142672: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:54:13.143084: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:54:13.143406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14622 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n",
      "2023-04-14 04:54:13.143495: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:54:13.143799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14622 MB memory:  -> device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:05.0, compute capability: 7.0\n",
      "2023-04-14 04:54:13.143870: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:54:13.144215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 14622 MB memory:  -> device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:06.0, compute capability: 7.0\n",
      "2023-04-14 04:54:13.144283: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-14 04:54:13.144567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 14622 MB memory:  -> device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:07.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.client import device_lib\n",
    "# device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv', header=None, names=['text','time','label'])\n",
    "test = pd.read_csv('./data/test.csv', header=None, names=['text','time','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list = train['text'].tolist()\n",
    "X_test_list = test['text'].tolist()\n",
    "y_train = train['label'].tolist()\n",
    "y_test = test['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 'allenai/longformer-base-4096'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer(X_train_list[:10], truncation=True, padding=True)\n",
    "# X_test = tokenizer(X_test, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('bigfile/X_train.pkl','wb') as f:\n",
    "#     pickle.dump(X_train,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bigfile/X_train.pkl','rb') as f:\n",
    "    X_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(X_train['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=4096, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(X_train),\n",
    "    y_train[:10]\n",
    "))\n",
    "\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "#     dict(X_test),\n",
    "#     y_test\n",
    "# ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"NG\", 1: \"Groomer\"}\n",
    "label2id = {\"NG\": 0, \"Groomer\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.optimizers.legacy import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path = \"bigfile/savem/training/cp-{epoch:04d}.ckpt\"\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001) #learning_rate=5e-5\n",
    "# loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
    "\n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     filepath=checkpoint_path, \n",
    "#     monitor='val_loss', \n",
    "#     save_best_only=True, \n",
    "#     save_weights_only=True, \n",
    "#     save_freq='epoch'\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFTrainer, TFTrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at allenai/longformer-base-4096 were not used when initializing TFLongformerForSequenceClassification: ['lm_head']\n",
      "- This IS expected if you are initializing TFLongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFLongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFLongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/trainer_tf.py:123: FutureWarning: The class `TFTrainer` is deprecated and will be removed in version 5 of Transformers. We recommend using native Keras instead, by calling methods like `fit()` and `predict()` directly on the model object. Detailed examples of the Keras style can be found in our examples at https://github.com/huggingface/transformers/tree/main/examples/tensorflow\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "training_args = TFTrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=5,              # total number of training epochs\n",
    "    per_device_train_batch_size=1,  # batch size per device during training\n",
    "    # per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    learning_rate= 0.0001,\n",
    "    # warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    # weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs'            # directory for storing logs\n",
    ")\n",
    "gpus = tf.config.list_logical_devices('GPU')\n",
    "strategy = tf.distribute.MirroredStrategy(gpus)\n",
    "with training_args.strategy.scope():\n",
    "    trainer_model = TFAutoModelForSequenceClassification.from_pretrained(M, num_labels=2) #, id2label=id2label, label2id=label2id)\n",
    "trainer = TFTrainer(\n",
    "    model=trainer_model,                 # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset= trainset,         # training dataset\n",
    "    # eval_dataset=val_dataset             # evaluation dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 19:42:18.733579: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "input: \"Placeholder/_2\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 10\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:0\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 610\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 610\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "INFO:tensorflow:batch_all_reduce: 270 all-reduces with algorithm = nccl, num_packs = 1\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 3 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Error reported to Coordinator: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/coordinator.py\", line 293, in stop_on_exception\n",
      "    yield\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/mirrored_run.py\", line 225, in _call_for_each_replica\n",
      "    t.has_paused.wait()\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 552, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 296, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_7502/49973641.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/trainer_tf.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    567\u001b[0m                         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed_training_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    943\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;31m# no_variable_creation function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m       _, _, filtered_flat_args = (\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[0;32m--> 133\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m    134\u001b[0m     return concrete_function._call_flat(\n\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeneralized_func_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_placeholder_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m           \u001b[0mconcrete_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m           \u001b[0mgraph_capture_container\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcrete_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_capture_func_lib\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mautograph_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_autograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mspec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1281\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36mbound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;31m# However, the replacer is still responsible for attaching self properly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;31m# TODO(mdan): Is it possible to do it here instead?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m   \u001b[0mweak_bound_method_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_method_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1263\u001b[0m                     \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1265\u001b[0;31m                     \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1266\u001b[0m                 ))\n\u001b[1;32m   1267\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/trainer_tf.py\u001b[0m in \u001b[0;36mtf__distributed_training_steps\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0mnb_instances_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_nb_instances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_step_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_instances_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                     \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf__distributed_training_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1314\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1315\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1316\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2893\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2894\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/mirrored_strategy.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    695\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     return mirrored_run.call_for_each_replica(\n\u001b[0;32m--> 697\u001b[0;31m         self._container_strategy(), fn, args, kwargs)\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m   def _configure(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/mirrored_run.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(strategy, fn, args, kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautograph_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/mirrored_run.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(distribution, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m       \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdistribute_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_result\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/coordinator.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, threads, stop_grace_period_secs, ignore_live_threads)\u001b[0m\n\u001b[1;32m    384\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex_instance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mex_instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mstragglers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mignore_live_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/coordinator.py\u001b[0m in \u001b[0;36mstop_on_exception\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \"\"\"\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m       \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=bare-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/mirrored_run.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(distribution, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_paused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m             \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_paused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at allenai/longformer-base-4096 were not used when initializing TFLongformerForSequenceClassification: ['lm_head']\n",
      "- This IS expected if you are initializing TFLongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFLongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFLongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "gpus = tf.config.list_logical_devices('GPU')\n",
    "strategy = tf.distribute.MirroredStrategy(gpus)\n",
    "with strategy.scope():\n",
    "    model = TFAutoModelForSequenceClassification.from_pretrained(M, num_labels=2) #, id2label=id2label, label2id=label2id)\n",
    "    # loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    #   from_logits=True,\n",
    "    #   reduction=tf.keras.losses.Reduction.NONE)\n",
    "    # def compute_loss(labels, predictions):\n",
    "    #     per_example_loss = loss_object(labels, predictions)\n",
    "    #     return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'], callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 01:59:59.002910: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "input: \"Placeholder/_2\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 10\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:0\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 610\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 610\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    trainset.shuffle(n).batch(1), epochs=1, batch_size=1,\n",
    "    # validation_data = val_dataset.shuffle(len(X_test['input_ids'])).batch(32),\n",
    "    # callbacks = [callback_earlystop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('lf_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights('savem/lf_w2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at allenai/longformer-base-4096 were not used when initializing TFLongformerForSequenceClassification: ['lm_head']\n",
      "- This IS expected if you are initializing TFLongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFLongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFLongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "new_model = TFAutoModelForSequenceClassification.from_pretrained(M, num_labels=2, id2label=id2label, label2id=label2id)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001) #learning_rate=5e-5\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
    "new_model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fe2ec200810>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.load_weights('savem/lf_w1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "\n",
    "# ë¡œë“œí•˜ê¸°\n",
    "\n",
    "text_classifier = TextClassificationPipeline(\n",
    "    tokenizer=tokenizer, \n",
    "    model=model, \n",
    "    framework='tf',\n",
    "    return_all_scores=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_classifier('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.non_trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<transformers.models.longformer.modeling_tf_longformer.TFLongformerForSequenceClassification at 0x7f9fae271c10>,\n",
       "  True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerMainLayer at 0x7f9f5c155ed0>,\n",
       "  True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerEmbeddings at 0x7f9a2c5809d0>,\n",
       "  True),\n",
       " (<keras.layers.normalization.layer_normalization.LayerNormalization at 0x7f9a2c588ed0>,\n",
       "  True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c588290>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerEncoder at 0x7f9a2c4a9750>,\n",
       "  True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerLayer at 0x7f9a2c4a9a90>,\n",
       "  True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerAttention at 0x7f9a2c4a9c10>,\n",
       "  True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerSelfAttention at 0x7f9a2c4a9d90>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c46f050>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c46f5d0>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c46f910>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c46fd10>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c543110>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c543550>, True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c543950>, True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c543b90>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerSelfOutput at 0x7f9a2c543e50>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c4d52d0>, True),\n",
       " (<keras.layers.normalization.layer_normalization.LayerNormalization at 0x7f9a2c4d5290>,\n",
       "  True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c4d5a90>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerIntermediate at 0x7f9a2c4d5c10>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c4d5fd0>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerOutput at 0x7f9a2c4d51d0>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c433690>, True),\n",
       " (<keras.layers.normalization.layer_normalization.LayerNormalization at 0x7f9a2c433650>,\n",
       "  True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c433e50>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerLayer at 0x7f9a2c4334d0>,\n",
       "  True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerAttention at 0x7f9a2c43c410>,\n",
       "  True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerSelfAttention at 0x7f9a2c43c590>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c43c810>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c43cc10>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3cf090>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3cf410>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3cf750>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3cfc10>, True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c3cffd0>, True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c3d5310>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerSelfOutput at 0x7f9a2c3d55d0>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3d58d0>, True),\n",
       " (<keras.layers.normalization.layer_normalization.LayerNormalization at 0x7f9a2c3d5950>,\n",
       "  True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c3d5e10>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerIntermediate at 0x7f9a2c3dc3d0>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3dc710>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerOutput at 0x7f9a2c3dc790>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3dcd50>, True),\n",
       " (<keras.layers.normalization.layer_normalization.LayerNormalization at 0x7f9a2c3dcdd0>,\n",
       "  True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c3e2590>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerLayer at 0x7f9a2c3e2810>,\n",
       "  True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerAttention at 0x7f9a2c3e2ad0>,\n",
       "  True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerSelfAttention at 0x7f9a2c3e2c50>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3e2f50>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3e63d0>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3e6790>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3e6b90>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3e6090>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3ef490>, True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c3ef850>, True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c3efad0>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerSelfOutput at 0x7f9a2c3efdd0>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3f6150>, True),\n",
       " (<keras.layers.normalization.layer_normalization.LayerNormalization at 0x7f9a2c3f61d0>,\n",
       "  True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c3f6990>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerIntermediate at 0x7f9a2c3f6c10>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3f6f50>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerOutput at 0x7f9a2c3f6fd0>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3fe5d0>, True),\n",
       " (<keras.layers.normalization.layer_normalization.LayerNormalization at 0x7f9a2c3fe650>,\n",
       "  True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c3fee90>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerLayer at 0x7f9a2c403110>,\n",
       "  True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerAttention at 0x7f9a2c403390>,\n",
       "  True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerSelfAttention at 0x7f9a2c403510>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c403810>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c403c50>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c408090>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c408450>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c408850>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c408d50>, True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c408150>, True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c38f3d0>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerSelfOutput at 0x7f9a2c38f6d0>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c38fa10>, True),\n",
       " (<keras.layers.normalization.layer_normalization.LayerNormalization at 0x7f9a2c38fa90>,\n",
       "  True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c38ff50>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerIntermediate at 0x7f9a2c395550>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c395890>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerOutput at 0x7f9a2c395910>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c395ed0>, True),\n",
       " (<keras.layers.normalization.layer_normalization.LayerNormalization at 0x7f9a2c4330d0>,\n",
       "  True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c39c750>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerLayer at 0x7f9a2c39c950>,\n",
       "  True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerAttention at 0x7f9a2c39cc10>,\n",
       "  True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerSelfAttention at 0x7f9a2c39cd50>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c39cfd0>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3a3450>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3a3850>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3a3c50>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3a9110>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3a9590>, True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c3a9990>, True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c3a9c10>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerSelfOutput at 0x7f9a2c3a9f10>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3af250>, True),\n",
       " (<keras.layers.normalization.layer_normalization.LayerNormalization at 0x7f9a2c3af2d0>,\n",
       "  True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c3afa90>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerIntermediate at 0x7f9a2c3afcd0>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3b6050>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerOutput at 0x7f9a2c3b60d0>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3b6690>, True),\n",
       " (<keras.layers.normalization.layer_normalization.LayerNormalization at 0x7f9a2c3b6710>,\n",
       "  True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c3b6f10>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerLayer at 0x7f9a2c3bb2d0>,\n",
       "  True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerAttention at 0x7f9a2c3bb490>,\n",
       "  True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerSelfAttention at 0x7f9a2c3bb610>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3bb910>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3bbd50>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3c21d0>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3c2550>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3c2950>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3c2e50>, True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c3c2250>, True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c3c9550>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerSelfOutput at 0x7f9a2c3c9850>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3c9b90>, True),\n",
       " (<keras.layers.normalization.layer_normalization.LayerNormalization at 0x7f9a2c3c9c10>,\n",
       "  True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c34e490>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerIntermediate at 0x7f9a2c34e6d0>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c34ea10>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerOutput at 0x7f9a2c34ea90>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3540d0>, True),\n",
       " (<keras.layers.normalization.layer_normalization.LayerNormalization at 0x7f9a2c354110>,\n",
       "  True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c354950>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerLayer at 0x7f9a2c354b90>,\n",
       "  True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerAttention at 0x7f9a2c354e50>,\n",
       "  True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerSelfAttention at 0x7f9a2c354fd0>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c35b310>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c35b750>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c35bb50>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c35bf50>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c362390>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c362890>, True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c362c90>, True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c362f50>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerSelfOutput at 0x7f9a2c368290>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3685d0>, True),\n",
       " (<keras.layers.normalization.layer_normalization.LayerNormalization at 0x7f9a2c368650>,\n",
       "  True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c368e90>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerIntermediate at 0x7f9a2c36e110>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c36e450>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerOutput at 0x7f9a2c36e4d0>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c36ea90>, True),\n",
       " (<keras.layers.normalization.layer_normalization.LayerNormalization at 0x7f9a2c36eb10>,\n",
       "  True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c36efd0>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerLayer at 0x7f9a2c3755d0>,\n",
       "  True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerAttention at 0x7f9a2c375890>,\n",
       "  True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerSelfAttention at 0x7f9a2c3759d0>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c375cd0>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c37a1d0>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c37a510>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c37a910>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c37ad10>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c382210>, True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c382650>, True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c382910>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerSelfOutput at 0x7f9a2c382c10>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c382f50>, True),\n",
       " (<keras.layers.normalization.layer_normalization.LayerNormalization at 0x7f9a2c382fd0>,\n",
       "  True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c388850>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerIntermediate at 0x7f9a2c388a90>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c388dd0>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerOutput at 0x7f9a2c388e50>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c30d450>, True),\n",
       " (<keras.layers.normalization.layer_normalization.LayerNormalization at 0x7f9a2c30d4d0>,\n",
       "  True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c30dd10>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerLayer at 0x7f9a2c30df50>,\n",
       "  True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerAttention at 0x7f9a2c313250>,\n",
       "  True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerSelfAttention at 0x7f9a2c3133d0>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3136d0>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c313ad0>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c313ed0>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c31a390>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c31a710>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c31ac10>, True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c31afd0>, True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c320350>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerSelfOutput at 0x7f9a2c320650>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c320990>, True),\n",
       " (<keras.layers.normalization.layer_normalization.LayerNormalization at 0x7f9a2c320a10>,\n",
       "  True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c320ed0>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerIntermediate at 0x7f9a2c3284d0>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c328810>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerOutput at 0x7f9a2c328890>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c328e50>, True),\n",
       " (<keras.layers.normalization.layer_normalization.LayerNormalization at 0x7f9a2c328ed0>,\n",
       "  True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c32d750>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerLayer at 0x7f9a2c3bb190>,\n",
       "  True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerAttention at 0x7f9a2c32dbd0>,\n",
       "  True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerSelfAttention at 0x7f9a2c32dd50>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c333090>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3334d0>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c3338d0>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c333cd0>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c33a190>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c33a610>, True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c33aa10>, True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c33ad10>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerSelfOutput at 0x7f9a2c33afd0>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c33e390>, True),\n",
       " (<keras.layers.normalization.layer_normalization.LayerNormalization at 0x7f9a2c33e410>,\n",
       "  True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c33ec50>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerIntermediate at 0x7f9a2c33ee90>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c345210>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerOutput at 0x7f9a2c345290>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c345850>, True),\n",
       " (<keras.layers.normalization.layer_normalization.LayerNormalization at 0x7f9a2c3458d0>,\n",
       "  True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c345d90>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerLayer at 0x7f9a2c2cd390>,\n",
       "  True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerAttention at 0x7f9a2c2cd650>,\n",
       "  True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerSelfAttention at 0x7f9a2c2cd7d0>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c2cdad0>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c2cdf10>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c2d4350>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c2d4750>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c2d4b50>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c2d8050>, True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c2d8490>, True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c2d8750>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerSelfOutput at 0x7f9a2c2d8a50>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c2d8d50>, True),\n",
       " (<keras.layers.normalization.layer_normalization.LayerNormalization at 0x7f9a2c2d8dd0>,\n",
       "  True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c2e0650>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerIntermediate at 0x7f9a2c2e0890>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c2e0bd0>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerOutput at 0x7f9a2c2e0c50>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c2e5250>, True),\n",
       " (<keras.layers.normalization.layer_normalization.LayerNormalization at 0x7f9a2c2e52d0>,\n",
       "  True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c2e5b10>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerLayer at 0x7f9a2c2e5d50>,\n",
       "  True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerAttention at 0x7f9a2c2ea050>,\n",
       "  True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerSelfAttention at 0x7f9a2c2ea1d0>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c2ea4d0>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c2ea910>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c2ead10>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c2f31d0>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c2f3550>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c2f3a50>, True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c2f3e50>, True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c2f9150>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerSelfOutput at 0x7f9a2c2f9450>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c2f9790>, True),\n",
       " (<keras.layers.normalization.layer_normalization.LayerNormalization at 0x7f9a2c2f9810>,\n",
       "  True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c2f9fd0>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerIntermediate at 0x7f9a2c2ff2d0>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c2ff610>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerOutput at 0x7f9a2c2ff690>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c2ffc50>, True),\n",
       " (<keras.layers.normalization.layer_normalization.LayerNormalization at 0x7f9a2c2ffcd0>,\n",
       "  True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c305550>, True),\n",
       " (<transformers.models.longformer.modeling_tf_longformer.TFLongformerClassificationHead at 0x7f9a2c4a9890>,\n",
       "  True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c2a2390>, True),\n",
       " (<keras.layers.regularization.dropout.Dropout at 0x7f9a2c2a2790>, True),\n",
       " (<keras.layers.core.dense.Dense at 0x7f9a2c2a2a90>, True)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model._get_trainable_state().items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_SCALAR_UPRANKING_ON',\n",
       " '_TF_MODULE_IGNORED_PROPERTIES',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_activity_regularizer',\n",
       " '_add_trackable',\n",
       " '_add_trackable_child',\n",
       " '_add_variable_with_custom_getter',\n",
       " '_assert_compile_was_called',\n",
       " '_assert_weights_created',\n",
       " '_auto_class',\n",
       " '_auto_get_config',\n",
       " '_auto_track_sub_layers',\n",
       " '_autocast',\n",
       " '_autographed_call',\n",
       " '_base_model_initialized',\n",
       " '_build_input_shape',\n",
       " '_call_spec',\n",
       " '_callable_losses',\n",
       " '_captured_weight_regularizer',\n",
       " '_cast_single_input',\n",
       " '_check_call_args',\n",
       " '_check_sample_weight_warning',\n",
       " '_checkpoint',\n",
       " '_checkpoint_dependencies',\n",
       " '_clear_losses',\n",
       " '_cluster_coordinator',\n",
       " '_compile_config',\n",
       " '_compile_from_config',\n",
       " '_compile_was_called',\n",
       " '_compiled_trainable_state',\n",
       " '_compute_dtype',\n",
       " '_compute_dtype_object',\n",
       " '_compute_output_and_mask_jointly',\n",
       " '_configure_steps_per_execution',\n",
       " '_create_repo',\n",
       " '_dedup_weights',\n",
       " '_deferred_dependencies',\n",
       " '_delete_tracking',\n",
       " '_deserialization_dependencies',\n",
       " '_deserialize_from_proto',\n",
       " '_distribute_reduction_method',\n",
       " '_distribution_strategy',\n",
       " '_dtype',\n",
       " '_dtype_policy',\n",
       " '_dynamic',\n",
       " '_eager_losses',\n",
       " '_expand_inputs_for_generation',\n",
       " '_expects_mask_arg',\n",
       " '_expects_training_arg',\n",
       " '_export_to_saved_model_graph',\n",
       " '_extract_past_from_model_output',\n",
       " '_flatten',\n",
       " '_flatten_layers',\n",
       " '_flatten_modules',\n",
       " '_from_config',\n",
       " '_functional_construction_call',\n",
       " '_gather_beams',\n",
       " '_gather_children_attribute',\n",
       " '_gather_saveables_for_checkpoint',\n",
       " '_get_callback_model',\n",
       " '_get_cell_name',\n",
       " '_get_compile_args',\n",
       " '_get_decoder_start_token_id',\n",
       " '_get_existing_metric',\n",
       " '_get_files_timestamps',\n",
       " '_get_input_masks',\n",
       " '_get_logits_processor',\n",
       " '_get_logits_warper',\n",
       " '_get_node_attribute_at_index',\n",
       " '_get_optimizer',\n",
       " '_get_resized_embeddings',\n",
       " '_get_resized_lm_head_bias',\n",
       " '_get_resized_lm_head_decoder',\n",
       " '_get_save_spec',\n",
       " '_get_trainable_state',\n",
       " '_get_unnested_name_scope',\n",
       " '_get_word_embedding_weight',\n",
       " '_handle_activity_regularization',\n",
       " '_handle_deferred_dependencies',\n",
       " '_handle_weight_regularization',\n",
       " '_in_multi_worker_mode',\n",
       " '_inbound_nodes',\n",
       " '_inbound_nodes_value',\n",
       " '_infer_output_signature',\n",
       " '_init_batch_counters',\n",
       " '_init_call_fn_args',\n",
       " '_init_set_name',\n",
       " '_initial_weights',\n",
       " '_input_spec',\n",
       " '_instrument_layer_creation',\n",
       " '_instrumented_keras_api',\n",
       " '_instrumented_keras_layer_class',\n",
       " '_instrumented_keras_model_class',\n",
       " '_is_compiled',\n",
       " '_is_graph_network',\n",
       " '_is_layer',\n",
       " '_is_model_for_instrumentation',\n",
       " '_jit_compile',\n",
       " '_keras_api_names',\n",
       " '_keras_api_names_v1',\n",
       " '_keras_tensor_symbolic_call',\n",
       " '_keys_to_ignore_on_load_missing',\n",
       " '_keys_to_ignore_on_load_unexpected',\n",
       " '_label_to_output_map',\n",
       " '_layout_map',\n",
       " '_load_own_variables',\n",
       " '_lookup_dependency',\n",
       " '_losses',\n",
       " '_map_resources',\n",
       " '_maybe_build',\n",
       " '_maybe_cast_inputs',\n",
       " '_maybe_create_attribute',\n",
       " '_maybe_initialize_input_ids_for_generation',\n",
       " '_maybe_initialize_trackable',\n",
       " '_maybe_load_initial_counters_from_ckpt',\n",
       " '_merge_criteria_processor_list',\n",
       " '_metrics',\n",
       " '_metrics_lock',\n",
       " '_must_restore_from_config',\n",
       " '_name',\n",
       " '_name_based_attribute_restore',\n",
       " '_name_based_restores',\n",
       " '_name_scope',\n",
       " '_name_scope_on_declaration',\n",
       " '_no_dependency',\n",
       " '_non_trainable_weights',\n",
       " '_obj_reference_counts',\n",
       " '_obj_reference_counts_dict',\n",
       " '_object_identifier',\n",
       " '_outbound_nodes',\n",
       " '_outbound_nodes_value',\n",
       " '_predict_counter',\n",
       " '_preload_simple_restoration',\n",
       " '_prepare_attention_mask_for_generation',\n",
       " '_prepare_decoder_input_ids_for_generation',\n",
       " '_prepare_encoder_decoder_kwargs_for_generation',\n",
       " '_prepare_model_inputs',\n",
       " '_preserve_input_structure_in_config',\n",
       " '_requires_load_weight_prefix',\n",
       " '_reset_compile_cache',\n",
       " '_resize_token_embeddings',\n",
       " '_restore_from_tensors',\n",
       " '_run_eagerly',\n",
       " '_save_checkpoint',\n",
       " '_save_experimental',\n",
       " '_save_own_variables',\n",
       " '_saved_model_arg_spec',\n",
       " '_saved_model_inputs_spec',\n",
       " '_seed_generator',\n",
       " '_self_name_based_restores',\n",
       " '_self_saveable_object_factories',\n",
       " '_self_setattr_tracking',\n",
       " '_self_tracked_trackables',\n",
       " '_self_unconditional_checkpoint_dependencies',\n",
       " '_self_unconditional_deferred_dependencies',\n",
       " '_self_unconditional_dependency_names',\n",
       " '_self_update_uid',\n",
       " '_serialize_to_proto',\n",
       " '_serialize_to_tensors',\n",
       " '_set_connectivity_metadata',\n",
       " '_set_dtype_policy',\n",
       " '_set_inputs',\n",
       " '_set_mask_keras_history_checked',\n",
       " '_set_mask_metadata',\n",
       " '_set_save_spec',\n",
       " '_set_trainable_state',\n",
       " '_set_training_mode',\n",
       " '_setattr_tracking',\n",
       " '_should_cast_single_input',\n",
       " '_should_compute_mask',\n",
       " '_should_eval',\n",
       " '_stateful',\n",
       " '_steps_per_execution',\n",
       " '_supports_masking',\n",
       " '_test_counter',\n",
       " '_tf_api_names',\n",
       " '_tf_api_names_v1',\n",
       " '_thread_local',\n",
       " '_track_trackable',\n",
       " '_track_variable',\n",
       " '_track_variables',\n",
       " '_trackable_children',\n",
       " '_trackable_saved_model_saver',\n",
       " '_tracking_metadata',\n",
       " '_train_counter',\n",
       " '_trainable',\n",
       " '_trainable_weights',\n",
       " '_training_state',\n",
       " '_unconditional_checkpoint_dependencies',\n",
       " '_unconditional_dependency_names',\n",
       " '_undeduplicated_weights',\n",
       " '_update_model_kwargs_for_generation',\n",
       " '_update_model_kwargs_for_xla_generation',\n",
       " '_update_trackables',\n",
       " '_update_uid',\n",
       " '_updated_config',\n",
       " '_updates',\n",
       " '_upload_modified_files',\n",
       " '_use_input_spec_as_call_signature',\n",
       " '_using_dummy_loss',\n",
       " '_v2_get_resized_embeddings',\n",
       " '_v2_get_resized_lm_head_bias',\n",
       " '_v2_resize_token_embeddings',\n",
       " '_v2_resized_token_embeddings',\n",
       " '_validate_and_get_metrics_result',\n",
       " '_validate_compile',\n",
       " '_validate_model_class',\n",
       " '_validate_model_kwargs',\n",
       " '_validate_target_and_loss',\n",
       " 'activity_regularizer',\n",
       " 'add_loss',\n",
       " 'add_metric',\n",
       " 'add_update',\n",
       " 'add_variable',\n",
       " 'add_weight',\n",
       " 'adjust_logits_during_generation',\n",
       " 'base_model_prefix',\n",
       " 'beam_search',\n",
       " 'build',\n",
       " 'built',\n",
       " 'call',\n",
       " 'can_generate',\n",
       " 'classifier',\n",
       " 'compile',\n",
       " 'compiled_loss',\n",
       " 'compiled_metrics',\n",
       " 'compute_dtype',\n",
       " 'compute_loss',\n",
       " 'compute_mask',\n",
       " 'compute_metrics',\n",
       " 'compute_output_shape',\n",
       " 'compute_output_signature',\n",
       " 'compute_transition_scores',\n",
       " 'config',\n",
       " 'config_class',\n",
       " 'contrastive_search',\n",
       " 'count_params',\n",
       " 'create_model_card',\n",
       " 'distribute_reduction_method',\n",
       " 'distribute_strategy',\n",
       " 'dtype',\n",
       " 'dtype_policy',\n",
       " 'dummy_inputs',\n",
       " 'dynamic',\n",
       " 'eager_serving',\n",
       " 'evaluate',\n",
       " 'evaluate_generator',\n",
       " 'finalize_state',\n",
       " 'fit',\n",
       " 'fit_generator',\n",
       " 'framework',\n",
       " 'from_config',\n",
       " 'from_pretrained',\n",
       " 'generate',\n",
       " 'generation_config',\n",
       " 'get_bias',\n",
       " 'get_config',\n",
       " 'get_input_at',\n",
       " 'get_input_embeddings',\n",
       " 'get_input_mask_at',\n",
       " 'get_input_shape_at',\n",
       " 'get_label_to_output_name_mapping',\n",
       " 'get_layer',\n",
       " 'get_lm_head',\n",
       " 'get_metrics_result',\n",
       " 'get_output_at',\n",
       " 'get_output_embeddings',\n",
       " 'get_output_layer_with_bias',\n",
       " 'get_output_mask_at',\n",
       " 'get_output_shape_at',\n",
       " 'get_prefix_bias_name',\n",
       " 'get_weight_paths',\n",
       " 'get_weights',\n",
       " 'greedy_search',\n",
       " 'hf_compute_loss',\n",
       " 'history',\n",
       " 'inbound_nodes',\n",
       " 'input',\n",
       " 'input_mask',\n",
       " 'input_names',\n",
       " 'input_shape',\n",
       " 'input_spec',\n",
       " 'inputs',\n",
       " 'layers',\n",
       " 'load_repo_checkpoint',\n",
       " 'load_weights',\n",
       " 'longformer',\n",
       " 'loss',\n",
       " 'losses',\n",
       " 'main_input_name',\n",
       " 'make_predict_function',\n",
       " 'make_test_function',\n",
       " 'make_train_function',\n",
       " 'metrics',\n",
       " 'metrics_names',\n",
       " 'name',\n",
       " 'name_or_path',\n",
       " 'name_scope',\n",
       " 'non_trainable_variables',\n",
       " 'non_trainable_weights',\n",
       " 'num_labels',\n",
       " 'num_parameters',\n",
       " 'optimizer',\n",
       " 'outbound_nodes',\n",
       " 'output',\n",
       " 'output_mask',\n",
       " 'output_names',\n",
       " 'output_shape',\n",
       " 'outputs',\n",
       " 'predict',\n",
       " 'predict_function',\n",
       " 'predict_generator',\n",
       " 'predict_on_batch',\n",
       " 'predict_step',\n",
       " 'prepare_inputs_for_generation',\n",
       " 'prepare_tf_dataset',\n",
       " 'prune_heads',\n",
       " 'push_to_hub',\n",
       " 'register_for_auto_class',\n",
       " 'reset_metrics',\n",
       " 'reset_states',\n",
       " 'resize_token_embeddings',\n",
       " 'run_eagerly',\n",
       " 'sample',\n",
       " 'save',\n",
       " 'save_pretrained',\n",
       " 'save_spec',\n",
       " 'save_weights',\n",
       " 'seed_generator',\n",
       " 'serving',\n",
       " 'serving_output',\n",
       " 'set_bias',\n",
       " 'set_input_embeddings',\n",
       " 'set_output_embeddings',\n",
       " 'set_weights',\n",
       " 'state_updates',\n",
       " 'stateful',\n",
       " 'stop_training',\n",
       " 'submodules',\n",
       " 'summary',\n",
       " 'supports_masking',\n",
       " 'supports_xla_generation',\n",
       " 'test_function',\n",
       " 'test_on_batch',\n",
       " 'test_step',\n",
       " 'to_json',\n",
       " 'to_yaml',\n",
       " 'train_function',\n",
       " 'train_on_batch',\n",
       " 'train_step',\n",
       " 'train_tf_function',\n",
       " 'trainable',\n",
       " 'trainable_variables',\n",
       " 'trainable_weights',\n",
       " 'updates',\n",
       " 'variable_dtype',\n",
       " 'variables',\n",
       " 'weights',\n",
       " 'with_name_scope']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    @traceback_utils.filter_traceback\n",
      "    def __call__(self, *args, **kwargs):\n",
      "        if self._layout_map is not None and not self.built:\n",
      "            # Note that this method is only overridden for DTensor and layout\n",
      "            # injection purpose.\n",
      "            # Capture the inputs and create graph input as replacement for model\n",
      "            # to initialize its weights first.\n",
      "            copied_args = copy.copy(args)\n",
      "            copied_kwargs = copy.copy(kwargs)\n",
      "\n",
      "            (\n",
      "                inputs,\n",
      "                copied_args,\n",
      "                copied_kwargs,\n",
      "            ) = self._call_spec.split_out_first_arg(copied_args, copied_kwargs)\n",
      "\n",
      "            def _convert_to_graph_inputs(x):\n",
      "                if isinstance(x, (tf.Tensor, np.ndarray, float, int)):\n",
      "                    x = tf.convert_to_tensor(x)\n",
      "                    return input_layer_module.Input(x.shape)\n",
      "\n",
      "            # TODO(scottzhu): maybe better handle mask and training flag.\n",
      "            inputs = tf.nest.map_structure(_convert_to_graph_inputs, inputs)\n",
      "            copied_args = tf.nest.map_structure(\n",
      "                _convert_to_graph_inputs, copied_args\n",
      "            )\n",
      "            copied_kwargs = tf.nest.map_structure(\n",
      "                _convert_to_graph_inputs, copied_kwargs\n",
      "            )\n",
      "\n",
      "            with layout_map_lib.layout_map_scope(self._layout_map):\n",
      "                # We ignore the result here.\n",
      "                super().__call__(inputs, *copied_args, **copied_kwargs)\n",
      "\n",
      "            layout_map_lib._map_subclass_model_variable(self, self._layout_map)\n",
      "\n",
      "        return super().__call__(*args, **kwargs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(new_model.__call__))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    @traceback_utils.filter_traceback\n",
      "    def fit(\n",
      "        self,\n",
      "        x=None,\n",
      "        y=None,\n",
      "        batch_size=None,\n",
      "        epochs=1,\n",
      "        verbose=\"auto\",\n",
      "        callbacks=None,\n",
      "        validation_split=0.0,\n",
      "        validation_data=None,\n",
      "        shuffle=True,\n",
      "        class_weight=None,\n",
      "        sample_weight=None,\n",
      "        initial_epoch=0,\n",
      "        steps_per_epoch=None,\n",
      "        validation_steps=None,\n",
      "        validation_batch_size=None,\n",
      "        validation_freq=1,\n",
      "        max_queue_size=10,\n",
      "        workers=1,\n",
      "        use_multiprocessing=False,\n",
      "    ):\n",
      "        \"\"\"Trains the model for a fixed number of epochs (iterations on a dataset).\n",
      "\n",
      "        Args:\n",
      "            x: Input data. It could be:\n",
      "              - A Numpy array (or array-like), or a list of arrays\n",
      "                (in case the model has multiple inputs).\n",
      "              - A TensorFlow tensor, or a list of tensors\n",
      "                (in case the model has multiple inputs).\n",
      "              - A dict mapping input names to the corresponding array/tensors,\n",
      "                if the model has named inputs.\n",
      "              - A `tf.data` dataset. Should return a tuple\n",
      "                of either `(inputs, targets)` or\n",
      "                `(inputs, targets, sample_weights)`.\n",
      "              - A generator or `keras.utils.Sequence` returning `(inputs,\n",
      "                targets)` or `(inputs, targets, sample_weights)`.\n",
      "              - A `tf.keras.utils.experimental.DatasetCreator`, which wraps a\n",
      "                callable that takes a single argument of type\n",
      "                `tf.distribute.InputContext`, and returns a `tf.data.Dataset`.\n",
      "                `DatasetCreator` should be used when users prefer to specify the\n",
      "                per-replica batching and sharding logic for the `Dataset`.\n",
      "                See `tf.keras.utils.experimental.DatasetCreator` doc for more\n",
      "                information.\n",
      "              A more detailed description of unpacking behavior for iterator\n",
      "              types (Dataset, generator, Sequence) is given below. If these\n",
      "              include `sample_weights` as a third component, note that sample\n",
      "              weighting applies to the `weighted_metrics` argument but not the\n",
      "              `metrics` argument in `compile()`. If using\n",
      "              `tf.distribute.experimental.ParameterServerStrategy`, only\n",
      "              `DatasetCreator` type is supported for `x`.\n",
      "            y: Target data. Like the input data `x`,\n",
      "              it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      "              It should be consistent with `x` (you cannot have Numpy inputs and\n",
      "              tensor targets, or inversely). If `x` is a dataset, generator,\n",
      "              or `keras.utils.Sequence` instance, `y` should\n",
      "              not be specified (since targets will be obtained from `x`).\n",
      "            batch_size: Integer or `None`.\n",
      "                Number of samples per gradient update.\n",
      "                If unspecified, `batch_size` will default to 32.\n",
      "                Do not specify the `batch_size` if your data is in the\n",
      "                form of datasets, generators, or `keras.utils.Sequence`\n",
      "                instances (since they generate batches).\n",
      "            epochs: Integer. Number of epochs to train the model.\n",
      "                An epoch is an iteration over the entire `x` and `y`\n",
      "                data provided\n",
      "                (unless the `steps_per_epoch` flag is set to\n",
      "                something other than None).\n",
      "                Note that in conjunction with `initial_epoch`,\n",
      "                `epochs` is to be understood as \"final epoch\".\n",
      "                The model is not trained for a number of iterations\n",
      "                given by `epochs`, but merely until the epoch\n",
      "                of index `epochs` is reached.\n",
      "            verbose: 'auto', 0, 1, or 2. Verbosity mode.\n",
      "                0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      "                'auto' defaults to 1 for most cases, but 2 when used with\n",
      "                `ParameterServerStrategy`. Note that the progress bar is not\n",
      "                particularly useful when logged to a file, so verbose=2 is\n",
      "                recommended when not running interactively (eg, in a production\n",
      "                environment).\n",
      "            callbacks: List of `keras.callbacks.Callback` instances.\n",
      "                List of callbacks to apply during training.\n",
      "                See `tf.keras.callbacks`. Note\n",
      "                `tf.keras.callbacks.ProgbarLogger` and\n",
      "                `tf.keras.callbacks.History` callbacks are created automatically\n",
      "                and need not be passed into `model.fit`.\n",
      "                `tf.keras.callbacks.ProgbarLogger` is created or not based on\n",
      "                `verbose` argument to `model.fit`.\n",
      "                Callbacks with batch-level calls are currently unsupported with\n",
      "                `tf.distribute.experimental.ParameterServerStrategy`, and users\n",
      "                are advised to implement epoch-level calls instead with an\n",
      "                appropriate `steps_per_epoch` value.\n",
      "            validation_split: Float between 0 and 1.\n",
      "                Fraction of the training data to be used as validation data.\n",
      "                The model will set apart this fraction of the training data,\n",
      "                will not train on it, and will evaluate\n",
      "                the loss and any model metrics\n",
      "                on this data at the end of each epoch.\n",
      "                The validation data is selected from the last samples\n",
      "                in the `x` and `y` data provided, before shuffling. This\n",
      "                argument is not supported when `x` is a dataset, generator or\n",
      "                `keras.utils.Sequence` instance.\n",
      "                If both `validation_data` and `validation_split` are provided,\n",
      "                `validation_data` will override `validation_split`.\n",
      "                `validation_split` is not yet supported with\n",
      "                `tf.distribute.experimental.ParameterServerStrategy`.\n",
      "            validation_data: Data on which to evaluate\n",
      "                the loss and any model metrics at the end of each epoch.\n",
      "                The model will not be trained on this data. Thus, note the fact\n",
      "                that the validation loss of data provided using\n",
      "                `validation_split` or `validation_data` is not affected by\n",
      "                regularization layers like noise and dropout.\n",
      "                `validation_data` will override `validation_split`.\n",
      "                `validation_data` could be:\n",
      "                  - A tuple `(x_val, y_val)` of Numpy arrays or tensors.\n",
      "                  - A tuple `(x_val, y_val, val_sample_weights)` of NumPy\n",
      "                    arrays.\n",
      "                  - A `tf.data.Dataset`.\n",
      "                  - A Python generator or `keras.utils.Sequence` returning\n",
      "                  `(inputs, targets)` or `(inputs, targets, sample_weights)`.\n",
      "                `validation_data` is not yet supported with\n",
      "                `tf.distribute.experimental.ParameterServerStrategy`.\n",
      "            shuffle: Boolean (whether to shuffle the training data\n",
      "                before each epoch) or str (for 'batch'). This argument is\n",
      "                ignored when `x` is a generator or an object of tf.data.Dataset.\n",
      "                'batch' is a special option for dealing\n",
      "                with the limitations of HDF5 data; it shuffles in batch-sized\n",
      "                chunks. Has no effect when `steps_per_epoch` is not `None`.\n",
      "            class_weight: Optional dictionary mapping class indices (integers)\n",
      "                to a weight (float) value, used for weighting the loss function\n",
      "                (during training only).\n",
      "                This can be useful to tell the model to\n",
      "                \"pay more attention\" to samples from\n",
      "                an under-represented class.\n",
      "            sample_weight: Optional Numpy array of weights for\n",
      "                the training samples, used for weighting the loss function\n",
      "                (during training only). You can either pass a flat (1D)\n",
      "                Numpy array with the same length as the input samples\n",
      "                (1:1 mapping between weights and samples),\n",
      "                or in the case of temporal data,\n",
      "                you can pass a 2D array with shape\n",
      "                `(samples, sequence_length)`,\n",
      "                to apply a different weight to every timestep of every sample.\n",
      "                This argument is not supported when `x` is a dataset, generator,\n",
      "                or `keras.utils.Sequence` instance, instead provide the\n",
      "                sample_weights as the third element of `x`.\n",
      "                Note that sample weighting does not apply to metrics specified\n",
      "                via the `metrics` argument in `compile()`. To apply sample\n",
      "                weighting to your metrics, you can specify them via the\n",
      "                `weighted_metrics` in `compile()` instead.\n",
      "            initial_epoch: Integer.\n",
      "                Epoch at which to start training\n",
      "                (useful for resuming a previous training run).\n",
      "            steps_per_epoch: Integer or `None`.\n",
      "                Total number of steps (batches of samples)\n",
      "                before declaring one epoch finished and starting the\n",
      "                next epoch. When training with input tensors such as\n",
      "                TensorFlow data tensors, the default `None` is equal to\n",
      "                the number of samples in your dataset divided by\n",
      "                the batch size, or 1 if that cannot be determined. If x is a\n",
      "                `tf.data` dataset, and 'steps_per_epoch'\n",
      "                is None, the epoch will run until the input dataset is\n",
      "                exhausted.  When passing an infinitely repeating dataset, you\n",
      "                must specify the `steps_per_epoch` argument. If\n",
      "                `steps_per_epoch=-1` the training will run indefinitely with an\n",
      "                infinitely repeating dataset.  This argument is not supported\n",
      "                with array inputs.\n",
      "                When using `tf.distribute.experimental.ParameterServerStrategy`:\n",
      "                  * `steps_per_epoch=None` is not supported.\n",
      "            validation_steps: Only relevant if `validation_data` is provided and\n",
      "                is a `tf.data` dataset. Total number of steps (batches of\n",
      "                samples) to draw before stopping when performing validation\n",
      "                at the end of every epoch. If 'validation_steps' is None,\n",
      "                validation will run until the `validation_data` dataset is\n",
      "                exhausted. In the case of an infinitely repeated dataset, it\n",
      "                will run into an infinite loop. If 'validation_steps' is\n",
      "                specified and only part of the dataset will be consumed, the\n",
      "                evaluation will start from the beginning of the dataset at each\n",
      "                epoch. This ensures that the same validation samples are used\n",
      "                every time.\n",
      "            validation_batch_size: Integer or `None`.\n",
      "                Number of samples per validation batch.\n",
      "                If unspecified, will default to `batch_size`.\n",
      "                Do not specify the `validation_batch_size` if your data is in\n",
      "                the form of datasets, generators, or `keras.utils.Sequence`\n",
      "                instances (since they generate batches).\n",
      "            validation_freq: Only relevant if validation data is provided.\n",
      "              Integer or `collections.abc.Container` instance (e.g. list, tuple,\n",
      "              etc.).  If an integer, specifies how many training epochs to run\n",
      "              before a new validation run is performed, e.g. `validation_freq=2`\n",
      "              runs validation every 2 epochs. If a Container, specifies the\n",
      "              epochs on which to run validation, e.g.\n",
      "              `validation_freq=[1, 2, 10]` runs validation at the end of the\n",
      "              1st, 2nd, and 10th epochs.\n",
      "            max_queue_size: Integer. Used for generator or\n",
      "              `keras.utils.Sequence` input only. Maximum size for the generator\n",
      "              queue.  If unspecified, `max_queue_size` will default to 10.\n",
      "            workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      "                only. Maximum number of processes to spin up\n",
      "                when using process-based threading. If unspecified, `workers`\n",
      "                will default to 1.\n",
      "            use_multiprocessing: Boolean. Used for generator or\n",
      "                `keras.utils.Sequence` input only. If `True`, use process-based\n",
      "                threading. If unspecified, `use_multiprocessing` will default to\n",
      "                `False`. Note that because this implementation relies on\n",
      "                multiprocessing, you should not pass non-picklable arguments to\n",
      "                the generator as they can't be passed easily to children\n",
      "                processes.\n",
      "\n",
      "        Unpacking behavior for iterator-like inputs:\n",
      "            A common pattern is to pass a tf.data.Dataset, generator, or\n",
      "          tf.keras.utils.Sequence to the `x` argument of fit, which will in fact\n",
      "          yield not only features (x) but optionally targets (y) and sample\n",
      "          weights.  Keras requires that the output of such iterator-likes be\n",
      "          unambiguous. The iterator should return a tuple of length 1, 2, or 3,\n",
      "          where the optional second and third elements will be used for y and\n",
      "          sample_weight respectively. Any other type provided will be wrapped in\n",
      "          a length one tuple, effectively treating everything as 'x'. When\n",
      "          yielding dicts, they should still adhere to the top-level tuple\n",
      "          structure.\n",
      "          e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
      "          features, targets, and weights from the keys of a single dict.\n",
      "            A notable unsupported data type is the namedtuple. The reason is\n",
      "          that it behaves like both an ordered datatype (tuple) and a mapping\n",
      "          datatype (dict). So given a namedtuple of the form:\n",
      "              `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
      "          it is ambiguous whether to reverse the order of the elements when\n",
      "          interpreting the value. Even worse is a tuple of the form:\n",
      "              `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
      "          where it is unclear if the tuple was intended to be unpacked into x,\n",
      "          y, and sample_weight or passed through as a single element to `x`. As\n",
      "          a result the data processing code will simply raise a ValueError if it\n",
      "          encounters a namedtuple. (Along with instructions to remedy the\n",
      "          issue.)\n",
      "\n",
      "        Returns:\n",
      "            A `History` object. Its `History.history` attribute is\n",
      "            a record of training loss values and metrics values\n",
      "            at successive epochs, as well as validation loss values\n",
      "            and validation metrics values (if applicable).\n",
      "\n",
      "        Raises:\n",
      "            RuntimeError: 1. If the model was never compiled or,\n",
      "            2. If `model.fit` is  wrapped in `tf.function`.\n",
      "\n",
      "            ValueError: In case of mismatch between the provided input data\n",
      "                and what the model expects or when the input data is empty.\n",
      "        \"\"\"\n",
      "        base_layer.keras_api_gauge.get_cell(\"fit\").set(True)\n",
      "        # Legacy graph support is contained in `training_v1.Model`.\n",
      "        version_utils.disallow_legacy_graph(\"Model\", \"fit\")\n",
      "        self._assert_compile_was_called()\n",
      "        self._check_call_args(\"fit\")\n",
      "        _disallow_inside_tf_function(\"fit\")\n",
      "\n",
      "        verbose = _get_verbosity(verbose, self.distribute_strategy)\n",
      "\n",
      "        if validation_split and validation_data is None:\n",
      "            # Create the validation data using the training data. Only supported\n",
      "            # for `Tensor` and `NumPy` input.\n",
      "            (\n",
      "                x,\n",
      "                y,\n",
      "                sample_weight,\n",
      "            ), validation_data = data_adapter.train_validation_split(\n",
      "                (x, y, sample_weight), validation_split=validation_split\n",
      "            )\n",
      "\n",
      "        if validation_data:\n",
      "            (\n",
      "                val_x,\n",
      "                val_y,\n",
      "                val_sample_weight,\n",
      "            ) = data_adapter.unpack_x_y_sample_weight(validation_data)\n",
      "\n",
      "        if self.distribute_strategy._should_use_with_coordinator:\n",
      "            self._cluster_coordinator = (\n",
      "                tf.distribute.experimental.coordinator.ClusterCoordinator(\n",
      "                    self.distribute_strategy\n",
      "                )\n",
      "            )\n",
      "\n",
      "        with self.distribute_strategy.scope(), training_utils.RespectCompiledTrainableState(  # noqa: E501\n",
      "            self\n",
      "        ):\n",
      "            # Creates a `tf.data.Dataset` and handles batch and epoch iteration.\n",
      "            data_handler = data_adapter.get_data_handler(\n",
      "                x=x,\n",
      "                y=y,\n",
      "                sample_weight=sample_weight,\n",
      "                batch_size=batch_size,\n",
      "                steps_per_epoch=steps_per_epoch,\n",
      "                initial_epoch=initial_epoch,\n",
      "                epochs=epochs,\n",
      "                shuffle=shuffle,\n",
      "                class_weight=class_weight,\n",
      "                max_queue_size=max_queue_size,\n",
      "                workers=workers,\n",
      "                use_multiprocessing=use_multiprocessing,\n",
      "                model=self,\n",
      "                steps_per_execution=self._steps_per_execution,\n",
      "            )\n",
      "\n",
      "            # Container that configures and calls `tf.keras.Callback`s.\n",
      "            if not isinstance(callbacks, callbacks_module.CallbackList):\n",
      "                callbacks = callbacks_module.CallbackList(\n",
      "                    callbacks,\n",
      "                    add_history=True,\n",
      "                    add_progbar=verbose != 0,\n",
      "                    model=self,\n",
      "                    verbose=verbose,\n",
      "                    epochs=epochs,\n",
      "                    steps=data_handler.inferred_steps,\n",
      "                )\n",
      "\n",
      "            self.stop_training = False\n",
      "            self.train_function = self.make_train_function()\n",
      "            self._train_counter.assign(0)\n",
      "            callbacks.on_train_begin()\n",
      "            training_logs = None\n",
      "            # Handle fault-tolerance for multi-worker.\n",
      "            # TODO(omalleyt): Fix the ordering issues that mean this has to\n",
      "            # happen after `callbacks.on_train_begin`.\n",
      "            steps_per_epoch_inferred = (\n",
      "                steps_per_epoch or data_handler.inferred_steps\n",
      "            )\n",
      "            (\n",
      "                data_handler._initial_epoch,\n",
      "                data_handler._initial_step,\n",
      "            ) = self._maybe_load_initial_counters_from_ckpt(\n",
      "                steps_per_epoch_inferred, initial_epoch\n",
      "            )\n",
      "            logs = None\n",
      "            for epoch, iterator in data_handler.enumerate_epochs():\n",
      "                self.reset_metrics()\n",
      "                callbacks.on_epoch_begin(epoch)\n",
      "                with data_handler.catch_stop_iteration():\n",
      "                    for step in data_handler.steps():\n",
      "                        with tf.profiler.experimental.Trace(\n",
      "                            \"train\",\n",
      "                            epoch_num=epoch,\n",
      "                            step_num=step,\n",
      "                            batch_size=batch_size,\n",
      "                            _r=1,\n",
      "                        ):\n",
      "                            callbacks.on_train_batch_begin(step)\n",
      "                            tmp_logs = self.train_function(iterator)\n",
      "                            if data_handler.should_sync:\n",
      "                                context.async_wait()\n",
      "                            # No error, now safe to assign to logs.\n",
      "                            logs = tmp_logs\n",
      "                            end_step = step + data_handler.step_increment\n",
      "                            callbacks.on_train_batch_end(end_step, logs)\n",
      "                            if self.stop_training:\n",
      "                                break\n",
      "\n",
      "                logs = tf_utils.sync_to_numpy_or_python_type(logs)\n",
      "                if logs is None:\n",
      "                    raise ValueError(\n",
      "                        \"Unexpected result of `train_function` \"\n",
      "                        \"(Empty logs). Please use \"\n",
      "                        \"`Model.compile(..., run_eagerly=True)`, or \"\n",
      "                        \"`tf.config.run_functions_eagerly(True)` for more \"\n",
      "                        \"information of where went wrong, or file a \"\n",
      "                        \"issue/bug to `tf.keras`.\"\n",
      "                    )\n",
      "                # Override with model metrics instead of last step logs\n",
      "                logs = self._validate_and_get_metrics_result(logs)\n",
      "                epoch_logs = copy.copy(logs)\n",
      "\n",
      "                # Run validation.\n",
      "                if validation_data and self._should_eval(\n",
      "                    epoch, validation_freq\n",
      "                ):\n",
      "                    # Create data_handler for evaluation and cache it.\n",
      "                    if getattr(self, \"_eval_data_handler\", None) is None:\n",
      "                        self._eval_data_handler = data_adapter.get_data_handler(\n",
      "                            x=val_x,\n",
      "                            y=val_y,\n",
      "                            sample_weight=val_sample_weight,\n",
      "                            batch_size=validation_batch_size or batch_size,\n",
      "                            steps_per_epoch=validation_steps,\n",
      "                            initial_epoch=0,\n",
      "                            epochs=1,\n",
      "                            max_queue_size=max_queue_size,\n",
      "                            workers=workers,\n",
      "                            use_multiprocessing=use_multiprocessing,\n",
      "                            model=self,\n",
      "                            steps_per_execution=self._steps_per_execution,\n",
      "                        )\n",
      "                    val_logs = self.evaluate(\n",
      "                        x=val_x,\n",
      "                        y=val_y,\n",
      "                        sample_weight=val_sample_weight,\n",
      "                        batch_size=validation_batch_size or batch_size,\n",
      "                        steps=validation_steps,\n",
      "                        callbacks=callbacks,\n",
      "                        max_queue_size=max_queue_size,\n",
      "                        workers=workers,\n",
      "                        use_multiprocessing=use_multiprocessing,\n",
      "                        return_dict=True,\n",
      "                        _use_cached_eval_dataset=True,\n",
      "                    )\n",
      "                    val_logs = {\n",
      "                        \"val_\" + name: val for name, val in val_logs.items()\n",
      "                    }\n",
      "                    epoch_logs.update(val_logs)\n",
      "\n",
      "                callbacks.on_epoch_end(epoch, epoch_logs)\n",
      "                training_logs = epoch_logs\n",
      "                if self.stop_training:\n",
      "                    break\n",
      "\n",
      "            if (\n",
      "                isinstance(self.optimizer, optimizer_experimental.Optimizer)\n",
      "                and epochs > 0\n",
      "            ):\n",
      "                self.optimizer.finalize_variable_values(\n",
      "                    self.trainable_variables\n",
      "                )\n",
      "\n",
      "            # If eval data_handler exists, delete it after all epochs are done.\n",
      "            if getattr(self, \"_eval_data_handler\", None) is not None:\n",
      "                del self._eval_data_handler\n",
      "            callbacks.on_train_end(logs=training_logs)\n",
      "            return self.history\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(new_model.fit))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 05:02:55.748295: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1096531968 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "a = tf.convert_to_tensor(X_train['input_ids'])\n",
    "del a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 217s 2s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = new_model.predict(a[:1000], batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_score = [np.argmax(e) for e in y_pred[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss, test_acc = new_model.evaluate(X_train['input_ids'],y_train verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "\n",
    "f1 = f1_score(y_train[:1000],y_pred_score)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFLongformerSequenceClassifierOutput(loss=None, logits=array([[ 1.9855249, -1.9520394],\n",
       "       [ 1.985525 , -1.9520394],\n",
       "       [ 1.9855248, -1.9520394],\n",
       "       ...,\n",
       "       [ 1.9855248, -1.9520395],\n",
       "       [ 1.9855248, -1.9520394],\n",
       "       [ 1.9855248, -1.9520394]], dtype=float32), hidden_states=None, attentions=None, global_attentions=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NG       0.97      1.00      0.98       970\n",
      "           G       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.97      1000\n",
      "   macro avg       0.48      0.50      0.49      1000\n",
      "weighted avg       0.94      0.97      0.96      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train[:1000], y_pred_score, target_names=['NG','G']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
